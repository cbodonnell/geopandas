{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTFS Stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a geopandas geodataframe from a GTFS feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a url for a GTFS data feed. Let's turn it into a flexible geodataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.mta.info/developers/data/nyct/subway/google_transit.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to import some modules from the [Python standard library](https://docs.python.org/3/library/)\n",
    "\n",
    "We also have to import some third party modules.\n",
    "\n",
    "Add the *conda-forge* channel to your base channel by running:\n",
    "\n",
    "`conda config --add channels conda-forge`\n",
    "\n",
    "You can then create an environment with these dependencies by running: \n",
    "\n",
    "`conda create --name geo_env --file package-list.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for converting gtfs zipfiles into pandas dataframes. The dataframes are stored in a python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gtfsZipToDataframes(zip):\n",
    "    # create a dictionary to store the dataframes\n",
    "    dataframes = {}\n",
    "\n",
    "    # check if the zipfile has the required files\n",
    "    required_files = ['agency.txt', 'stops.txt', 'routes.txt', 'trips.txt', 'stop_times.txt']\n",
    "\n",
    "    has_required_files = [req_file in (file.filename for file in zip.filelist) for req_file in required_files]\n",
    "\n",
    "    if all(has_required_files):\n",
    "        # also check if there are any files not part of the gtfs standard and alert the user\n",
    "        standard_files = required_files + [\n",
    "            'shapes.txt', 'stop_times.txt', 'calendar.txt', 'calendar_dates.txt',\n",
    "            'fare_attributes.txt', 'fare_rules.txt', 'frequencies.txt', 'transfers.txt',\n",
    "            'pathways.txt', 'levels.txt', 'translations.txt', 'feed_info.txt', 'attributions.txt'\n",
    "        ]\n",
    "\n",
    "        # for each file in the list\n",
    "        for file in zip.filelist:\n",
    "            file_name = file.filename\n",
    "            # check that it is one of the standard files\n",
    "            if any(standard_file_name == file_name for standard_file_name in standard_files):\n",
    "                # open the file, read the data into a pandas dataframe, and add that to the dictionary\n",
    "                with zip.open(file_name) as f:\n",
    "                    bytes = f.read()\n",
    "                    s = str(bytes, 'utf-8')\n",
    "                    data = StringIO(s)\n",
    "                    df = pd.read_csv(data, low_memory=False)\n",
    "                    name = file_name.split('.txt')[0]\n",
    "                    dataframes[name] = df\n",
    "            else:\n",
    "                print('%s is not part of the gtfs specification!' % file_name)\n",
    "    else:\n",
    "        missing_files = [required_files[i] for i, has_file in enumerate(has_required_files) if not has_file]\n",
    "        raise Exception('GTFS feed does not have the required file(s): %s' % ' '.join(missing_files))\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function and list the resulting dataframes. The number of dataframes will vary between different gtfs sources.\n",
    "\n",
    "*You can also work with a local copy of the data for improved performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip = zipfile.ZipFile('data/nyc_subways.zip')\n",
    "r = requests.get(url)\n",
    "zip = ZipFile(BytesIO(r.content))\n",
    "gtfs_dataframes = gtfsZipToDataframes(zip)\n",
    "list(gtfs_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the agency dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency = gtfs_dataframes['agency']\n",
    "agency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the routes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = gtfs_dataframes['routes']\n",
    "routes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the agency and routes dataframes on the agency_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_routes = agency.join(\n",
    "    routes.set_index('agency_id'),\n",
    "    on='agency_id'\n",
    ")\n",
    "agency_routes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the trips datframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = gtfs_dataframes['trips']\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the trips and routes dataframes on the route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_trips = agency_routes.join(\n",
    "    trips.set_index('route_id'),\n",
    "    on='route_id'\n",
    ")\n",
    "routes_trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the stop_times dataframe. It links the stops to the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times = gtfs_dataframes['stop_times']\n",
    "stop_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the shapes and trips on the shape_id column. Let's also drop a bunch of columns that no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stop_times = routes_trips.join(\n",
    "    stop_times.set_index('trip_id'),\n",
    "    on='trip_id'\n",
    ")\n",
    "\n",
    "trips_stop_times.drop(\n",
    "    [\n",
    "        'service_id',\n",
    "        'trip_id',\n",
    "        'trip_headsign',\n",
    "        'direction_id',\n",
    "        'block_id',\n",
    "        'shape_dist_traveled'\n",
    "    ], \n",
    "    axis=1,\n",
    "    errors='ignore',\n",
    "    inplace=True\n",
    ")\n",
    "trip_stop_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the stops dataframe. This contains the spatial data describing the location of each stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = gtfs_dataframes['stops']\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the stops and the stop times on the stop_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stops = stops.join(\n",
    "    trip_stop_times.set_index('stop_id'),\n",
    "    on='stop_id'\n",
    ")\n",
    "trip_stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the unique route ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(routes.route_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part... We're going to transform this data into a geodataframe. Additional notes describing each step are provided in the code comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to store the stops for each route\n",
    "route_list = []\n",
    "\n",
    "# for each unique route_id\n",
    "for route_id in routes.route_id.unique():\n",
    "    \n",
    "    # get the route shapes\n",
    "    route_stops = trip_stops.loc[trip_stops.route_id == route_id]\n",
    "    \n",
    "    # check if there are stops\n",
    "    if route_stops.size > 0:\n",
    "        \n",
    "        # get the unique stop points for the route\n",
    "        route_stops = route_stops.drop_duplicates(\n",
    "            subset=['stop_id', 'stop_lat', 'stop_lon'],\n",
    "            keep='first'\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # add a shapely geometry column\n",
    "        route_stops['geometry'] = route_stops.apply(\n",
    "            lambda row: geometry.Point(row.stop_lon, row.stop_lat),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # we no longer need the original lat lon columns, so we can drop them\n",
    "        route_stops.drop(\n",
    "            [\n",
    "                'stop_lat',\n",
    "                'stop_lon'\n",
    "            ], \n",
    "            axis=1,\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # append the stops to the route list\n",
    "        route_list.append(route_stops)\n",
    "\n",
    "# create a geodataframe from the route list\n",
    "network_stops = gpd.GeoDataFrame(pd.concat(route_list)).reset_index(drop=True)\n",
    "network_stops.set_crs(4236, inplace=True) # set the spatial reference\n",
    "network_stops.to_crs(epsg=3857, inplace=True) # project the coordinates\n",
    "network_stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a route color and set a default, if none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_color = '000000'\n",
    "if 'route_color' in network_stops.columns:\n",
    "    network_stops.route_color.fillna(default_color, inplace=True)\n",
    "else:\n",
    "    network_stops.route_color = default_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = network_stops.plot(color='#' + network_stops.route_color, figsize=(10, 10))\n",
    "ctx.add_basemap(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextily provides a number of basemap sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ctx.providers.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at CartoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ctx.providers.CartoDB.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Positron tileset gives us a nice light background so we can easily see our routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = network_stops.plot(color='#' + network_stops.route_color, figsize=(10, 10))\n",
    "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
